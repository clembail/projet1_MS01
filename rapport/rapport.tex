\documentclass{article}
\usepackage[a4paper, margin=3cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{derivative}
\usepackage[most]{tcolorbox}
\tcbuselibrary{listingsutf8}
\usepackage{graphicx}
\usepackage{float}

\title{Projet 1 : MS01}
\author{Clément Baillet et Paul Michel}
\date{}

\begin{document}
\maketitle


\section{Méthode de Jacobi}


Dans toute la suite du rapport, les exemples sont réalisés pour les données suivantes : $U_0 = 1$, $\Omega = \,]0, 1[ \times \,]0, 1[$, $\alpha = 0,5$ ; pour cette partie, on fixe une tolérance en précision de $10^{-6}$ ainsi qu'un nombre maximal d'itérations à $10 000$. Pour un nombre de points intérieurs $N = 50$ (selon $x$ et selon $y$), on converge après $4235$ itérations avec une erreur finale légèrement inférieure à $10^{-6}$ :

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{test_jacobi_seq.png}
    \caption{Exemple d'exécution du code séquentiel - méthode de Jacobi}
    \label{fig:Jacseq}
\end{figure}

En effectuant des tests  pour $N_x \in [50,100,150,200,250]$, on observe une tendance $n_{iter} \propto N_x^{1,35}$. Le fait que l'on trouve 1,35 plutôt que 2 est peut-être dû au fait que garder $N_y=50$ réduise la dépendance pure $N_x^2$; cela est éventuellement influencé par le critère d'arrêt pour des petites grilles comme celles étudiées.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{courbe_log_log_jacobi.png}
    \caption{Evolution du nombre d'itérations en fonction de $N_x$ - méthode de Jacobi}
    \label{fig:loglogJac}
\end{figure}

\section{Méthode de Gauss-Seidel}
Pour le même jeu de données, on converge plus rapidement grâce à la technique de Gauss-Seidel :

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{test_gaussseidel_seq.png}
    \caption{Exemple d'exécution du code séquentiel - méthode de Gauss-Seidel}
    \label{fig:GSseq}
\end{figure}

De même que pour Jacobi, en effectuant des tests  pour $N_x \in [50,100,150,200,250]$, on observe une tendance $n_{iter} \propto N_x^{1,37}$. A nouveau, il est possible que la loi asymptotique s'observe mieux avec davantage de tests pour des $N_x$ plus élevés.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{courbe_log_log_gs.png}
    \caption{Evolution du nombre d'itérations en fonction de $N_x$ - méthode de Gauss-Seidel}
    \label{fig:loglogGS}
\end{figure}

\section{Comparaison des deux approches}
Dans la méthode de Jacobi, on met à jour $u$ à la fin de chaque boucle, alors que pour Gauss-Seidel on le fait dans la boucle même. Cela implique l'utilisation de 2 tableaux représentant $u$ pour Jacobi, alors qu'un seul suffit pour Gauss-Seidel. Cette observation sur le plan logique des méthodes est confirmée par la différence du nombre d'itérations avant convergence : Gauss-Seidel est une méthode presque deux fois plus rapide que celle de Jacobi en ce sens d'après les figures $1$ et $2$. Ceci corrobore la théorie mathématique, mais nous ne la développerons pas dans ce rapport. Plus encore, en comparant le temps d'exécution entre les deux approches, on remarque une fois de plus que celle de Gauss-Seidel est plus rapide.

La comparaison des deux précédentes parties sur l'évolution du nombre d'itérations en fonction de la taille de la grille se visualise sur la figure \ref{fig:comparaison}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{comparaison_j_gs.png}
    \caption{Comparaison de l'évolution du nombre d'itérations en fonction de $N_x$}
    \label{fig:comparaison}
\end{figure}


\section{Parallélisation du code : Jacobi}


Dans cette sous-section uniquement, les tests ont été réalisés sur une grille 500x500 avec 1 jusqu'à 6 processus sur une machine de l'ENSTA. La Figure \ref{fig:strongJac} permet l'étude de la scalabilité forte de la méthode de Jacobi:


\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{strong_scaling_jacobi.png}
    \caption{Scalabilité forte - méthode de Jacobi}
    \label{fig:strongJac}
\end{figure}

On observe que le speedup croît avec le nombre de processeurs tant qu'on se sert de moins de 4 coeurs, limite physique du CPU après laquelle le speedup s'effondre. Sur la partie croissante, on observe une bonne scalabilité forte pour la méthode de Jacobi. On peut constater ces mêmes résultats en étudiant l'évolution de l'efficacité en fonction du nombre de processeurs sur la Figure \ref{fig:weakJac}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{weak_scaling_jacobi.png}
    \caption{Scalabilité faible - méthode de Jacobi}
    \label{fig:weakJac}
\end{figure}

Il est intéressant de remarquer qu'après avoir effectué des tests sur différentes tailles de grilles, on constate pour un petit format (50x50) un scaling moindre que pour des plus grandes grilles (300x300). Cela semble cohérent car une plus grande taille rend la parallélisation davantage intéressante.


\section{Parallélisation du code : Gauss-Seidel}


Nous avons parallélisé le code de Gauss-Seidel en utilisant la méthode dites "Rouge/Noir", qui consiste à découper le domaine en deux partie indépendante dans la boucle for. Bien que les différents tests ont montré que généralement Gauss-Seidel convergeait en moins d'itérations que Jacobi (idéalement 2x moins), la scalabilité forte de cette méthode est moins bonne que celle de Jacobi, notamment à cause d'un plus grand nombre de communications avec la méthode de parallélisation employée. Le graphique suivant montre les résultats obtenus pour la méthode de Gauss-Seidel et compare avec la scalabilité forte de Jacobi :

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{strong_scaling_gs.png}
    \caption{Scalabilité forte - Gauss-Seidel et comparaison}
    \label{fig:strongGS}
\end{figure}


\section{Tests avec Cholesky}


Pour les tests sur le mésocentre Cholesky, dans un premier temps, nous avons testé la scalabilité forte pour une tolérance de $10^{-8}$, et sur un domaine fixe de $256\times 256$. Pour la scalabilité faible, nous avons augmenté progressivement la taille du domaine, en passant de $16\times 256$ à $512\times 256$. Les Figures \ref{fig:strongCholeskySmol} et \ref{fig:weakCholeskySmol} montrent les deux scalabilités avec les données obtenus.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Scalabilité_Forte_Speedup}
    \caption{Scalabilité faible sur petits domaines - Cholesky}
    \label{fig:strongCholeskySmol}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Scalabilité_Faible_Efficacité}
    \caption{Scalabilité faible sur petits domaines - Cholesky}
    \label{fig:weakCholeskySmol}
\end{figure}

Pour le speedup, on observe bien une augmentation quasi linéaire en fonction du nombre de processus (mais qui ne l'est pas parfaitement à cause du temps pris par les communications MPI). L'efficacité quant à elle, reste relativement proche de $1$, sans l'être parfaitement également à cause des communications.

Dans un second temps, nous avons voulu effectuer les mêmes tests, mais avec des domaines beaucoup plus grand: nous sommes parti d'un domaine $64\times 256$, et sommes monté progressivement jusqu'à $4096\times 256$. Malheureusement les résultats sont beaucoup moins concluants (cf Figures \ref{fig:weakCholeskyBig}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Scalabilité_Faible_Efficacité}
    \caption{Scalabilité faible sur des grands domaines - Cholesky}
    \label{fig:weakCholeskyBig}
\end{figure}

\end{document}